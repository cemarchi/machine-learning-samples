{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Regressão Logistíca\n",
    "\n",
    "<p> É um dos métodos de aprendizado de máquina mais conhecidos. Utiliza conceitos de estatística e probabilidade para analisar uma ou mais variáveis (<i>features</i>) independentes para predizer uma classe mais apropriada.</p>\n",
    "\n",
    "<p>A função logística é utilizada para estimar essa relação entre as várias independentes com a váriavel dependente, onde a função é uma <b>sigmoid</b> assemelhando-se a um 'S' no plano, transformando qualquer valor no intervalor de zero e um.</p>\n",
    "\n",
    "<p>Embora a regressão logística seja conhecida pelo modelo de classificação binária (binominal), pode-se aplica-la também para categorias ordenadas (três ou mais classes que possuem uma ordem determinada, por exemplo ruim, bom ou ótimo) e multinomial (três ou mais categorias não ordenadas entre si).</p>\n",
    "\n",
    "## Vantagens\n",
    "\n",
    "<ul>\n",
    "<li>Predição de probabilidade, podendo ser útil quando necessita de medidas de probabilidades, por exemplo ajustar os valores para classificar se um e-mail é <i>spam</i> ou não</li>\n",
    "<li>Pouco risco de <i>overfitting</i></li>\n",
    "<li>Flexibilidade de parâmetro de regularização (ajusta a borda de linearidade) para redução de erro no modelo</li>\n",
    "<li>Eficiente para grandes conjuntos de dados</li>\n",
    "<li>Não requer recursos computacionais</li>\n",
    "<li>Desempenho melhor que outros algoritmos de aprendizado de máquina com poucos dados de treinamento</li>\n",
    "</ul>\n",
    "\n",
    "## Desvantagens\n",
    "\n",
    "<ul>\n",
    "<li>Requer preparação de dados, incluindo normalização e escala</li>\n",
    "<li>Não consegue tratar dados faltantes</li>\n",
    "<li>Limitado para alguns casos. Utilizado apenas para métodos de classificação</li>\n",
    "<li>Destinado apenas para modelos lineares.</li>\n",
    "<li>Sensível dados com ruídos</li>\n",
    "<li>Para melhor predição, é necessário remover variáveis com alta correção, pode-se utilizar correlação de <i>Pearson</i> (variaveis seguem uma relação linear ou distribuição normal), <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\">aqui</a></li>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exemplo\n",
    "\n",
    "Vejamos um exemplo para criar modelo preditivo utilizando o algoritmo Random Forest para classificação de flores de íris.\n",
    "\n",
    "Dataset: UCI Iris Dataset\n",
    "Esse conjunto de dados de íris contém quatro variáveis (features) ​​que medem várias partes das flores da íris de três espécies relacionadas (target). A utilização desse conjunto de dados é muito comum pela comunidade de aprendizado de máquina, pois os dados exigem muito pouco pré-processamento, sendo ideal para o nosso exemplo onde o foco é na utilização do algoritmo.\n",
    "\n",
    "Caso tenha interesse em conhecer mais sobre esse conjunto de dado, por favor vide [aqui](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Importação dos pacotes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "source": [
    "### Carregamento do conjunto de dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris( return_X_y = True)"
   ]
  },
  {
   "source": [
    "### Configuração dos parâmetros do algoritmo\n",
    "<p>O algoritmo Regressão Logística requer poucos parâmetros de configuração. Vejamos a seguir uma breve descrição do parâmetro e também dos valores mais adequados de utilização.</p>\n",
    "\n",
    "<ul>\n",
    "<li><b>tol</b>: valor de tolerância para critérios de parada. Costuma-se aplicar valores pequenos com o intuito de evitar paradas rápidas, evitando do algoritmo não convergir.</li>\n",
    "<li><b>penalty</b>: usado para especificar a norma usada na penalização, sendo uma foma de impedir que os coeficientes se ajustem tão perfeitamente ao excesso de ajuste. Essas penalidades devem ser utilizadas de acordo com o solucionador (<i>solver</i>): L1 (a soma dos pesos) para 'liblinear'e 'saga', L2 (soma do quadrado dos pesos) apenas para 'newton-cg', 'sag' e 'lbfgs' solucionadores; elasticnet é uma combinação linear de regularização L1 e L2, suportado apenas para solucionados 'saga'.</li>\n",
    "<li><b>C</b>: corresponde ao parâmetro de regularização inversa, onde uma variável de controle que retém a modificação de força da regularização ao ser posicionada inversamente ao regulador. Valores baixos fortalece a regularização, então o mais indicado é utilizar maiores valores.</li>\n",
    "<li><b>solver</b>: represent o algoritmo para tratar o problema de otimização, podendo ser liblinear (ideal para pequenos conjuntos de dados e para classe binária), newton-cg (problemas multiclasse), lbfgs (problemas multiclasse), saga (recomendado para grandes conjuntos de dados e para problemas multiclasse) e sag (usado para grandes conjuntos de dados e para problemas multiclasse).</li>\n",
    "<li><b>max_iter</b>: define o número máximo de iterações pelo solucionador durante o ajuste do modelo. Valores baixos podem não encontrar melhores resultados enquanto de valores altos podem aumentar o tempo de treinamento. É interessante utilizar valores altos para conjuntos de dados complexos.</li>\n",
    "</ul>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tols = np.arange(0.0001, 0.1, 0.0005)\n",
    "c_range = 1.5 ** np.arange(-3, 13)\n",
    "\n",
    "params = {\n",
    "    'lg__tol': tols,\n",
    "    'lg__penalty': ['l2', 'elasticnet'],\n",
    "    'lg__C': c_range,\n",
    "    'lg__solver': ['newton-cg', 'sag', 'saga', 'lbfgs'], # apenas esses pois são multinomial\n",
    "    'lg__max_iter': range(100, 1000, 50)}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('lg', LogisticRegression(multi_class='multinomial'))])"
   ]
  },
  {
   "source": [
    "### Inicia o treinamento da inteligência com espaço de busca"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('scaler',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('lg',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=100,\n",
       "                                                                 multi_class='multinomial',\n",
       "                                                                 n_jobs=None,\n",
       "                                                                 penalty='l2',\n",
       "                                                                 random_state=None,\n",
       "                                                                 solver='lbf...\n",
       "       0.0801, 0.0806, 0.0811, 0.0816, 0.0821, 0.0826, 0.0831, 0.0836,\n",
       "       0.0841, 0.0846, 0.0851, 0.0856, 0.0861, 0.0866, 0.0871, 0.0876,\n",
       "       0.0881, 0.0886, 0.0891, 0.0896, 0.0901, 0.0906, 0.0911, 0.0916,\n",
       "       0.0921, 0.0926, 0.0931, 0.0936, 0.0941, 0.0946, 0.0951, 0.0956,\n",
       "       0.0961, 0.0966, 0.0971, 0.0976, 0.0981, 0.0986, 0.0991, 0.0996])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_macro', verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "lgc_search = RandomizedSearchCV(pipeline, \n",
    "                                param_distributions=params, \n",
    "                                n_iter=200,\n",
    "                                cv=3,\n",
    "                                scoring = 'f1_macro',\n",
    "                                verbose=False,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "lgc_search.fit(X, y)"
   ]
  },
  {
   "source": [
    "### Resultados\n",
    "<p>Os resultados apresentados aqui dão uma ideia da qualidade do modelo gerado. Vale ressaltar que o propósito deste exemplo é no entendimento e configuração do algoritmo.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params:\n{'lg__tol': 0.0381, 'lg__solver': 'sag', 'lg__penalty': 'l2', 'lg__max_iter': 250, 'lg__C': 38.443359375}\nBest score: 0.9734104394445952\nClassifier: Pipeline(memory=None,\n         steps=[('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('lg',\n                 LogisticRegression(C=38.443359375, class_weight=None,\n                                    dual=False, fit_intercept=True,\n                                    intercept_scaling=1, l1_ratio=None,\n                                    max_iter=250, multi_class='multinomial',\n                                    n_jobs=None, penalty='l2',\n                                    random_state=None, solver='sag', tol=0.0381,\n                                    verbose=0, warm_start=False))],\n         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "classifier_lg = lgc_search.best_estimator_ \n",
    "print(f'Best params:\\n{lgc_search.best_params_}')\n",
    "print(f'Best score: {lgc_search.best_score_}')\n",
    "print(f'Classifier: {classifier_lg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}