{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Classificador Gaussiano Naive Bayes\n",
    "\n",
    "<p>Naive Bayes é um algoritmo de classificação baseado na teoria de Bayes (<a href=\"https://pt.wikipedia.org/wiki/Teorema_de_Bayes\">teorema</a>) em que consiste na probabilidade de cada evento ocorrer, não levando em consideração a correlação entre as variáveis (<i>features</i>), ou seja, o algoritmo assume que os preditores são condicionalmente independentes um dos outros.</p>\n",
    "\n",
    "<p>À propósito, a biblioteca <b>scikit learn</b> possui três tipos de aprendizado por máquina que permite construir modelos bayesianos, incluindo <b>Gaussiano</b> que assume que os preditores (<i>features</i>) seguem uma distribuição normal; <b>Multinominal</b> destinado para dados de contagens discretas; e <b>Bernoulli</b> utilizado quando os preditores são vetores binários.</p>\n",
    "\n",
    "## Vantagens\n",
    "\n",
    "<ul>\n",
    "<li>Fácil implementação</li>\n",
    "<li>Simples e muito rápido</li>\n",
    "<li>Resistênte a dados com ruídos</li>\n",
    "<li>Não há risco de <i>overfitting</i></li>\n",
    "<li>Eficiente para grandes conjuntos de dados</li>\n",
    "<li>Não requer recursos computacionais</li>\n",
    "<li>Desempenho melhor que outros algoritmos de aprendizado de máquina com poucos dados de treinamento</li>\n",
    "</ul>\n",
    "\n",
    "## Desvantagens\n",
    "\n",
    "<ul>\n",
    "<li>Assume que as variáveis são independentes o que é muito difícil no mundo real. Nesse caso o ideal é remover variáveis com alta correção, pode-se utilizar correlações de <i>Pearson</i> (variaveis seguem uma relação linear ou distribuição normal) ou <i>Spearman</i> (variáveis não seguem uma relação linear ou nem uma distribuição normal), <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\">aqui</a></li>\n",
    "<li>As preditores devem seguir uma distribuição normal, caso não siga é necessário utilizar alguma técnica de transformação para convertê-las numa distribuição normal (<i><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer\">PowerTransformation</a></i>)</li>\n",
    "<li>Não possibilita trabalhar com regressão</li>\n",
    "<li>Quando o conjunto de dados de teste tem uma variável categórica de uma categoria que não estava presente no conjunto de dados de treinamento, o modelo atribuirá probabilidade zero e não será capaz de fazer quaisquer previsões a esse respeito (conhecido como '<i>Zero Frequency</i>'), portanto será necessário usar uma técnica de suavização (<i>smoothing</i>) para resolver este problema.</li>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exemplo\n",
    "\n",
    "Vejamos um exemplo para criar modelo preditivo utilizando o algoritmo Random Forest para classificação de flores de íris.\n",
    "\n",
    "Dataset: UCI Iris Dataset\n",
    "Esse conjunto de dados de íris contém quatro variáveis (features) ​​que medem várias partes das flores da íris de três espécies relacionadas (target). A utilização desse conjunto de dados é muito comum pela comunidade de aprendizado de máquina, pois os dados exigem muito pouco pré-processamento, sendo ideal para o nosso exemplo onde o foco é na utilização do algoritmo.\n",
    "\n",
    "Caso tenha interesse em conhecer mais sobre esse conjunto de dado, por favor vide [aqui](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset).\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Importação dos pacotes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "source": [
    "### Carregamento do conjunto de dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris( return_X_y = True)"
   ]
  },
  {
   "source": [
    "### Configuração dos parâmetros do algoritmo\n",
    "<p>O algoritmo Naive Bayes requer poucos parâmetros de configuração, por exemplo no Gaussiano apenas um parâmetro é necessário. Vejamos a seguir uma breve descrição do parâmetro e também dos valores mais adequados de utilização.</p>\n",
    "\n",
    "<ul>\n",
    "<li><b>var_smoothing</b>: valor para tratar <i>Zero Frequency</i>. O ideial que esse valor seja muito pequeno.</li>\n",
    "</ul>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gnb__var_smoothing': np.logspace(-2,-15, num=1000)}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('gnb', GaussianNB())])"
   ]
  },
  {
   "source": [
    "### Inicia o treinamento da inteligência com espaço de busca"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('gnb', GaussianNB())]),\n",
       "                   n_iter=300, n_jobs=-1,\n",
       "                   param_distributions={'gnb__var_smoothing': array([1.00000000e-02, 9.70480888e-03, 9.41833153e-03, 9.14031075e-03,\n",
       "       8.87049689e-03, 8.60864770e-03, 8.35452806e-03, 8.10790981e-03,\n",
       "       7.86857151e-03, 7.63629826e-03, 7.41088152e-03, 7.19211887e-03...\n",
       "       1.99204571e-15, 1.93324229e-15, 1.87617469e-15, 1.82079168e-15,\n",
       "       1.76704353e-15, 1.71488197e-15, 1.66426018e-15, 1.61513269e-15,\n",
       "       1.56745541e-15, 1.52118552e-15, 1.47628147e-15, 1.43270295e-15,\n",
       "       1.39041083e-15, 1.34936714e-15, 1.30953502e-15, 1.27087871e-15,\n",
       "       1.23336350e-15, 1.19695570e-15, 1.16162263e-15, 1.12733256e-15,\n",
       "       1.09405471e-15, 1.06175918e-15, 1.03041699e-15, 1.00000000e-15])},\n",
       "                   scoring='f1_macro', verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "gnc_search = RandomizedSearchCV(pipeline, \n",
    "                                param_distributions=params, \n",
    "                                n_iter=300,\n",
    "                                cv=3,\n",
    "                                scoring = 'f1_macro',\n",
    "                                verbose=False,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "gnc_search.fit(X, y)"
   ]
  },
  {
   "source": [
    "### Resultados\n",
    "<p>Os resultados apresentados aqui dão uma ideia da qualidade do modelo gerado. Vale ressaltar que o propósito deste exemplo é no entendimento e configuração do algoritmo.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params:\n{'gnb__var_smoothing': 7.09334120498799e-06}\nBest score: 0.9396454340398047\nClassifier: Pipeline(steps=[('scaler', StandardScaler()),\n                ('gnb', GaussianNB(var_smoothing=7.09334120498799e-06))])\n"
     ]
    }
   ],
   "source": [
    "classifier_gn = gnc_search.best_estimator_ \n",
    "print(f'Best params:\\n{gnc_search.best_params_}')\n",
    "print(f'Best score: {gnc_search.best_score_}')\n",
    "print(f'Classifier: {classifier_gn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}