{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Classificador KNN\n",
    "\n",
    "<p>Esse classificador é baseado no algoritmo KNN, é considerado como é um dos mais simples algoritmos de aprendizado de máquina. A construção desse modelo consiste apenas no armazenamento do conjunto de dados de treinamento para realizar a predição.</p>\n",
    "\n",
    "<p>Para fazer a predição para um novo ponto de dados (<i>features</i>), o algoritmo encontra os pontos de dados mais próximos (vizinhos) do seu conjunto de dados de treinamento em que esse resultado configura a previsão do classificador.</p>\n",
    "\n",
    "## Vantagens\n",
    "\n",
    "<ul>\n",
    "<li>Facilidade de compreensão</li>\n",
    "<li>Robusto para dados de treinamento com ruídos</li>\n",
    "<li>É mais efetivo para conjunto de dados de treinamento grande</li>\n",
    "<li>É muito útil para dados não-lineares</li>\n",
    "<li>Pode ser utilizado tanto para classificação como para regressão</i></li>\n",
    "<li>Não paramétrico</li>\n",
    "<li>Tem uma relativa boa acurácia</li>\n",
    "<li>Não requer normalização dos dados</li>\n",
    "</ul>\n",
    "\n",
    "## Desvantagens\n",
    "\n",
    "<ul>\n",
    "<li>Dificuldade de encontrar o melhor valor 'k' e também pode dispender tempo </i>\n",
    "<li>Necessário poder computacional e recursos</li>\n",
    "<li>É muito sensível para escala de dados, sendo necessário o uso de normalizadores</li>\n",
    "<li>Não é indicado para dados com alta dimensionalidade</li>\n",
    "<li>Muitos parâmetros de configuração</li>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exemplo\n",
    "\n",
    "Vejamos um exemplo para criar modelo preditivo utilizando o algoritmo Random Forest para classificação de flores de íris.\n",
    "\n",
    "Dataset: UCI Iris Dataset\n",
    "Esse conjunto de dados de íris contém quatro variáveis (features) ​​que medem várias partes das flores da íris de três espécies relacionadas (target). A utilização desse conjunto de dados é muito comum pela comunidade de aprendizado de máquina, pois os dados exigem muito pouco pré-processamento, sendo ideal para o nosso exemplo onde o foco é na utilização do algoritmo.\n",
    "\n",
    "Caso tenha interesse em conhecer mais sobre esse conjunto de dado, por favor vide [aqui](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset).\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Importação dos pacotes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "source": [
    "### Carregamento do conjunto de dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris( return_X_y = True)"
   ]
  },
  {
   "source": [
    "### Configuração dos parâmetros do algoritmo\n",
    "<p>KNN contém vários parâmetros configuráveis e isso aumenta a complexidade de utilização. Vejamos a seguir uma breve descrição dos parâmetros mais utilizados e também os valores mais adequados de utilização.</p>\n",
    "\n",
    "<ul>\n",
    "<li><b>n_neighbors</b>: número de vizinhos utilizados próximos ao ponto de verificação. Pode ser interessante procurar por 'k' menores, pois pode ajudar tanto para alvos que estejam misturados quanto para alvos que tem uma divisão mais clara.</li>\n",
    "<li><b>weights</b>: função de peso para predição, podendo ser uniforme (todos os pontos tem o mesmo peso), pela distância (peso pelo inverso de sua distância, vizinhos mais próximos de um ponto de consulta terão uma influência maior do que vizinhos que estão mais distantes) e customizado. A utilização de de um ou outro pode ser benéfica dependendo da disposição dos pontos no espaço.</li>\n",
    "<li><b>algorithm</b>: algoritmo utilizado para calcular a distância entre os vizinhos, podendo ser BallTree, KDTree, força bruta e auto. O mais comun é utilizar 'auto', pois o melhor algoritmo é escolhido com base no conjunto de dados de treinamento.</li>\n",
    "<li><b>leaf_size</b>: Tamanho da folha para os algoritmos BallTree e KDTree. Valor definido impacta na velocidade de construção e na busca, mas também em recursos empregados para armazenar a árvore. Para definir esse valor, pode-se levar em consideração o tamanho do conjunto de dados, recursos computacionais e tempo de treinamento.</li>\n",
    "<li><b>p</b>: parâmetro de potência para a métrica, podendo utilizar distância de manhattan (l1) e euclediana (l2) para valor igual a 1 ou distância minkowski para valor igual a 2.</li>\n",
    "<li><b>metric</b>: corresponde a métrica de distância usada na árvore. Há várias métricas disponíveis para uso, entretanto cada uma delas pode ser mais adequada dependendo do tipo de dados do conjunto. Mais informações das métricas disponíveis, vide <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric\">aqui</a>.</li>\n",
    "</ul>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'knn__n_neighbors': range(3, 30, 1),\n",
    "    'knn__weights': ['uniform','distance'],\n",
    "    'knn__algorithm': ['auto'],\n",
    "    'knn__leaf_size': range(1, 30, 2),\n",
    "    'knn__p': [1,2],\n",
    "    'knn__metric': ['minkowski', 'chebyshev']}\n",
    "            \n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('knn', KNeighborsClassifier())])"
   ]
  },
  {
   "source": [
    "### Inicia o treinamento da inteligência com espaço de busca"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('scaler',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('knn',\n",
       "                                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                                   leaf_size=30,\n",
       "                                                                   metric='minkowski',\n",
       "                                                                   metric_params=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   n_neighbors=5,\n",
       "                                                                   p=2,\n",
       "                                                                   weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=500, n_jobs=-1,\n",
       "                   param_distributions={'knn__algorithm': ['auto'],\n",
       "                                        'knn__leaf_size': range(1, 30, 2),\n",
       "                                        'knn__metric': ['minkowski',\n",
       "                                                        'chebyshev'],\n",
       "                                        'knn__n_neighbors': range(3, 30),\n",
       "                                        'knn__p': [1, 2],\n",
       "                                        'knn__weights': ['uniform',\n",
       "                                                         'distance']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_macro', verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "knnc_search = RandomizedSearchCV(pipeline, \n",
    "                                 param_distributions=params, \n",
    "                                 n_iter=500,\n",
    "                                 cv=3,\n",
    "                                 scoring = 'f1_macro',\n",
    "                                 verbose=False,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "knnc_search.fit(X, y)"
   ]
  },
  {
   "source": [
    "### Resultados\n",
    "<p>Os resultados apresentados aqui dão uma ideia da qualidade do modelo gerado. Vale ressaltar que o propósito deste exemplo é no entendimento e configuração do algoritmo.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params:\n{'knn__weights': 'distance', 'knn__p': 2, 'knn__n_neighbors': 9, 'knn__metric': 'minkowski', 'knn__leaf_size': 7, 'knn__algorithm': 'auto'}\nBest score: 0.9732191687362466\nClassifier: Pipeline(memory=None,\n         steps=[('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('knn',\n                 KNeighborsClassifier(algorithm='auto', leaf_size=7,\n                                      metric='minkowski', metric_params=None,\n                                      n_jobs=None, n_neighbors=9, p=2,\n                                      weights='distance'))],\n         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "classifier_rf = knnc_search.best_estimator_ \n",
    "print(f'Best params:\\n{knnc_search.best_params_}')\n",
    "print(f'Best score: {knnc_search.best_score_}')\n",
    "print(f'Classifier: {classifier_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}